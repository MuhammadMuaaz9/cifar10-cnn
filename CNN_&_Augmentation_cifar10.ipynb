{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGDQS4WAWFzI"
      },
      "source": [
        "In this notebook, we train a CNN on augmented images from the CIFAR-10 database.\n",
        "\n",
        "### 1. Load CIFAR-10 Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDSZqzHibiJm"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGtUqSHEWFzN"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# load the pre-shuffled train and test data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCcIsYZ7WFzP"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmO5apfWFzQ"
      },
      "source": [
        "### 2. Visualize the First 20 Training Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1hP6_06WFzR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "for i in range(36):\n",
        "    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(x_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwLnWTFtWFzR"
      },
      "source": [
        "### 3. Rescale the Images by Dividing Every Pixel in Every Image by 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhKs2WM4WFzS"
      },
      "outputs": [],
      "source": [
        "# rescale [0,255] --> [0,1]\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIhJkTMcWFzS"
      },
      "source": [
        "### 4.  Break Dataset into Training, Testing, and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nN5TIvfWFzT"
      },
      "outputs": [],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hf6vwH8WFzT"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "# break training set into training and validation sets\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# one-hot encode the labels\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "y_valid = to_categorical(y_valid, num_classes)\n",
        "\n",
        "# print shape of training set\n",
        "print('x_train shape:', x_train.shape)\n",
        "\n",
        "# print number of training, validation, and test images\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_valid.shape[0], 'validation samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSevTd-UWFzT"
      },
      "source": [
        "### 5. Create and Configure Augmented Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Kc13vLWFzU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create and configure augmented image generator\n",
        "datagen_train = ImageDataGenerator(\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
        "    horizontal_flip=True) # randomly flip images horizontally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZE7mWPdWFzU"
      },
      "source": [
        "### 6. Visualize Original and Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6tUVaaVWFzU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# take subset of training data\n",
        "x_train_subset = x_train[:12]\n",
        "\n",
        "# visualize subset of training data\n",
        "fig = plt.figure(figsize=(20,2))\n",
        "for i in range(0, len(x_train_subset)):\n",
        "    ax = fig.add_subplot(1, 12, i+1)\n",
        "    ax.imshow(x_train_subset[i])\n",
        "fig.suptitle('Subset of Original Training Images', fontsize=20)\n",
        "plt.show()\n",
        "\n",
        "# visualize augmented images\n",
        "fig = plt.figure(figsize=(20,2))\n",
        "for x_batch in datagen_train.flow(x_train_subset, batch_size=12):\n",
        "    for i in range(0, 12):\n",
        "        ax = fig.add_subplot(1, 12, i+1)\n",
        "        ax.imshow(x_batch[i])\n",
        "    fig.suptitle('Augmented Images', fontsize=20)\n",
        "    plt.show()\n",
        "    break;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59XLwCerWFzU"
      },
      "source": [
        "### 7. Define the Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuU4SjBGWFzU"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "J-Sr83IaWFzU",
        "outputId": "01c8f816-5ffc-4b28-ac7a-cf3bcda1f8bc"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdhYEqN1WFzV"
      },
      "source": [
        "### 8. Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBje5QiKWFzV"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3zkyaVqWFzV"
      },
      "source": [
        "### 9. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KJHn_dSWFzV"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW6H8wX5WFzV",
        "outputId": "698072ea-171e-48e9-ae58-326e146bda0e"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 70\n",
        "\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "validation_steps = x_valid.shape[0] // batch_size\n",
        "\n",
        "# create a callback to save the best weights during training\n",
        "checkpointer = ModelCheckpoint(filepath='aug_model.weights.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "# train the model\n",
        "history = model.fit(datagen_train.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=epochs, verbose=1, callbacks=[checkpointer],\n",
        "                    validation_data = (x_valid, y_valid),\n",
        "                    validation_steps = validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urlt_-m2WFzV"
      },
      "source": [
        "### 10. Load the Model with the Best Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpUZHJFmWFzW"
      },
      "outputs": [],
      "source": [
        "# load the weights that yielded the best validation accuracy\n",
        "model.load_weights('aug_model.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqAU5zhDWFzW"
      },
      "source": [
        "### 11. Calculate Classification Accuracy on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYLGfTdMWFzW",
        "outputId": "10a57a8d-0125-4045-9e1c-96d689fcd6e7"
      },
      "outputs": [],
      "source": [
        "# evaluate and print test accuracy\n",
        "result = model.evaluate(x_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sugJ-GOmXM0S",
        "outputId": "f54db0a4-55d0-498d-e34c-29fe9a9fe92c"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\\nAccuracy on training set is {}\".format(history.history[\"accuracy\"][-1]))\n",
        "print(\"\\nAccuracy on test set is {}\".format(result[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSY_nsrp0a37"
      },
      "source": [
        "Loss Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Dxr776dr0WGY",
        "outputId": "8f4c8a5d-856b-4357-d0d8-8f1507347276"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.legend()\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KOKgrZX1GZz"
      },
      "source": [
        "Accuracy Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5jSzSVwj1DPq",
        "outputId": "626584b0-73df-410a-a4cd-e280dee9c278"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U_1iQx51Pby"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s4tZPNm1PCr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "PPn-7YET1UDw",
        "outputId": "184054bd-9da9-4176-8230-241ef0e8f0c4"
      },
      "outputs": [],
      "source": [
        "# Predict and convert to labels\n",
        "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'],\n",
        "            yticklabels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'])\n",
        "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F8ppMYG1nqk",
        "outputId": "87810656-b9ce-47c9-b9e1-285488f5e33f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=[\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
